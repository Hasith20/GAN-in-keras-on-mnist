{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_input(img, ax):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y]<thresh else 'black')\n",
    "\n",
    "#fig = plt.figure(figsize = (12, 12)) \n",
    "#ax = fig.add_subplot(111)\n",
    "#visualize_input(X_train[0], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(network, val):\n",
    "    network.trainable = val\n",
    "    #for l in network.layers:\n",
    "        #l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set the dimensions of the noise\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g = Sequential()\n",
    "g.add(Dense(128, input_shape=(z_dim, ), activation=LeakyReLU(alpha=0.01)))\n",
    "g.add(Dense(256, activation=LeakyReLU(alpha=0.01)))\n",
    "g.add(Dense(512, activation=LeakyReLU(alpha=0.01)))\n",
    "g.add(Dense(1024, activation=LeakyReLU(alpha=0.01)))\n",
    "g.add(Dense(784, activation='sigmoid'))  # Values between 0 and 1\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "g.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "d = Sequential()\n",
    "d.add(Dense(1024, input_shape=(784, ), activation=LeakyReLU(alpha=0.01)))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(512, activation=LeakyReLU(alpha=0.01)))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(256, activation=LeakyReLU(alpha=0.01)))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(128, activation=LeakyReLU(alpha=0.01)))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(1, activation='sigmoid'))  # Values between 0 and 1\n",
    "\n",
    "optimizer = Adam(lr=0.002)\n",
    "d.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "d.trainable = False\n",
    "input = Input(shape=(z_dim, ))\n",
    "hidden = g(input)\n",
    "output = d(hidden)\n",
    "gan = Model(input, output)\n",
    "\n",
    "optimizer = RMSprop(lr=0.002)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    d_acc = [v[1] for v in losses[\"D\"]]\n",
    "    g_acc = [v[1] for v in losses[\"G\"]]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.plot(d_acc, label=\"Discriminator accuracy\")\n",
    "    plt.plot(g_acc, label=\"Generator accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_generated(n_ex=6, dim=(1, 6), figsize=(10, 7)):\n",
    "    noise = np.random.uniform(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(n_ex, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up a vector (dict) to store the losses\n",
    "losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "    for e in tqdm_notebook(range(epochs), leave=False):\n",
    "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in tqdm_notebook(range(batchCount)):\n",
    "            # Create a batch by drawing random index numbers from the training set\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "            # Create noise vectors for the generator\n",
    "            noise = np.random.uniform(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            \n",
    "            # Generate the images from the noise\n",
    "            generated_images = g.predict(noise)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            # Create labels\n",
    "            y = np.zeros([2 * BATCH_SIZE])\n",
    "            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing\n",
    "\n",
    "            # Train discriminator on generated images\n",
    "            make_trainable(d, True)\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.uniform(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            y2 = np.ones([BATCH_SIZE])\n",
    "            make_trainable(d, False)\n",
    "            g_loss = gan.train_on_batch(noise, y2)\n",
    "\n",
    "        # Only store losses from final batch of epoch\n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        # Update the plots\n",
    "        if e == 0 or e%plt_frq == plt_frq - 1:\n",
    "            plot_generated()\n",
    "    plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train(epochs=200, plt_frq=20, BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
